{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compressed files & archives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T08:41:56.253278Z",
     "start_time": "2018-11-14T08:41:56.233394Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import gzip\n",
    "from pathlib import Path\n",
    "import random\n",
    "import shutil\n",
    "import tarfile\n",
    "import tempfile\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing & reading gzip files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can directly write to or read from a compressed file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T08:41:56.383968Z",
     "start_time": "2018-11-14T08:41:56.264873Z"
    }
   },
   "outputs": [],
   "source": [
    "gzip_file = Path.cwd() / 'data.gz'\n",
    "with gzip.open(gzip_file, 'wb') as file:\n",
    "    for _ in range(500):\n",
    "        line = ''.join(random.choices('ACGT', k=80) + ['\\n']).encode()\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T08:41:56.422571Z",
     "start_time": "2018-11-14T08:41:56.397171Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12984"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gzip_file.lstat().st_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T08:41:56.460270Z",
     "start_time": "2018-11-14T08:41:56.428659Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: 9973\n",
      "C: 10067\n",
      "G: 9997\n",
      "T: 9963\n",
      "total = 40000\n"
     ]
    }
   ],
   "source": [
    "with gzip.open(gzip_file, 'rb') as file:\n",
    "    count = {symbol: 0 for symbol in 'ACGT'}\n",
    "    for line in file:\n",
    "        for symbol in line.decode(encoding='utf8'):\n",
    "            if symbol in count:\n",
    "                count[symbol] += 1\n",
    "    for symbol, nr in count.items():\n",
    "        print(f'{symbol}: {nr}')\n",
    "    print(f'total = {sum(count.values())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the gzip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T08:41:56.479149Z",
     "start_time": "2018-11-14T08:41:56.469539Z"
    }
   },
   "outputs": [],
   "source": [
    "gzip_file.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing & reading TAR files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a directory and some data files to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T08:42:06.558102Z",
     "start_time": "2018-11-14T08:41:56.485676Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = Path.cwd() / 'data'\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "nr_files = 5\n",
    "nr_symbols = 10000\n",
    "for file_nr in range(nr_files):\n",
    "    time.sleep(2)\n",
    "    file = data_dir / f'data_{file_nr + 1:02d}.txt'\n",
    "    with file.open('w') as data_file:\n",
    "        data = ''.join(random.choices('ACGT', k=nr_symbols))\n",
    "        print(data, file=data_file, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the data files to a compressed TAR file, and show the compression ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T08:42:06.699808Z",
     "start_time": "2018-11-14T08:42:06.587100Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_04.txt: 10000 bytes\n",
      "data_05.txt: 10000 bytes\n",
      "data_02.txt: 10000 bytes\n",
      "data_03.txt: 10000 bytes\n",
      "data_01.txt: 10000 bytes\n",
      "data.tar.gz: 15846 bytes (31.69%)\n"
     ]
    }
   ],
   "source": [
    "tar_path = Path('data.tar.gz')\n",
    "total_data_size = 0\n",
    "with tarfile.open(tar_path, 'w:gz') as tar_file:\n",
    "    for file in data_dir.iterdir():\n",
    "        data_size = file.lstat().st_size\n",
    "        total_data_size += data_size\n",
    "        print(f'{file.name}: {data_size} bytes')\n",
    "        tar_file.add(file.relative_to(Path.cwd()))\n",
    "size = tar_path.lstat().st_size\n",
    "print(f'{tar_path.name}: {size} bytes ({size/total_data_size:.2%})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the data directory in the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T08:42:06.716661Z",
     "start_time": "2018-11-14T08:42:06.705015Z"
    }
   },
   "outputs": [],
   "source": [
    "shutil.rmtree(data_dir.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meta-information can be retrieved from the compressed TAR file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T08:42:06.753911Z",
     "start_time": "2018-11-14T08:42:06.730204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/data_04.txt: 10000 bytes, last modified 2023-07-31 14:29:21\n",
      "data/data_05.txt: 10000 bytes, last modified 2023-07-31 14:29:23\n",
      "data/data_02.txt: 10000 bytes, last modified 2023-07-31 14:29:17\n",
      "data/data_03.txt: 10000 bytes, last modified 2023-07-31 14:29:19\n",
      "data/data_01.txt: 10000 bytes, last modified 2023-07-31 14:29:15\n"
     ]
    }
   ],
   "source": [
    "with tarfile.open(tar_path, 'r') as tar_file:\n",
    "    for tar_info in tar_file:\n",
    "        date = datetime.strftime(datetime.fromtimestamp(tar_info.mtime), '%Y-%m-%d %H:%M:%S')\n",
    "        print(f'{tar_info.name}: {tar_info.size} bytes, last modified {date}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract and process a single file at the time.  All files are in a compressed TAR file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T08:42:06.847963Z",
     "start_time": "2018-11-14T08:42:06.761532Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: 12576\n",
      "C: 12504\n",
      "G: 12379\n",
      "T: 12541\n",
      "total = 50000\n"
     ]
    }
   ],
   "source": [
    "tmp_dir = Path.cwd() / 'tmp'\n",
    "count = {symbol: 0 for symbol in 'ACGT'}\n",
    "with tarfile.open(tar_path, 'r') as tar_file:\n",
    "    for tar_info in tar_file:\n",
    "        tar_file.extract(tar_info, path=tmp_dir)\n",
    "        data_file = tmp_dir / tar_info.name\n",
    "        with data_file.open('r') as file:\n",
    "            for line in file:\n",
    "                for symbol in line:\n",
    "                    if symbol in count:\n",
    "                        count[symbol] += 1\n",
    "        data_file.unlink()\n",
    "for symbol, nr in count.items():\n",
    "    print(f'{symbol}: {nr}')\n",
    "print(f'total = {sum(count.values())}')\n",
    "shutil.rmtree(tmp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Important security note:* do not extract an unvalidated archive, it may contains files that will extract files in unexpected directories. This is *especially* important when running a script with superuser privileges!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the compressed TAR file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T08:42:06.875670Z",
     "start_time": "2018-11-14T08:42:06.857883Z"
    }
   },
   "outputs": [],
   "source": [
    "tar_path.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
